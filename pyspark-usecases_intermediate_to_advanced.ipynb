{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97c4c4a-a93b-41ea-a7af-499cfeae8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/01 19:01:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/01 19:01:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/02/01 19:01:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.5.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session\n",
    "spark = SparkSession.builder.appName(\"PySparkSteppingUp\").getOrCreate()\n",
    "\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3141f5c5-6b71-43db-8542-2c288e63c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------+-----------+\n",
      "| id|   name|age|salary| department|\n",
      "+---+-------+---+------+-----------+\n",
      "|  1|  Alice| 30| 70000|         HR|\n",
      "|  2|    Bob| 35| 80000|Engineering|\n",
      "|  3|Charlie| 25| 50000|  Marketing|\n",
      "|  4|  David| 40| 90000|Engineering|\n",
      "|  5|    Eva| 28| 60000|         HR|\n",
      "|  6|  Frank| 32| 75000|  Marketing|\n",
      "|  7|   Gina| 27| 55000|Engineering|\n",
      "|  8|  Harry| 31| 70000|         HR|\n",
      "|  9|    Ivy| 29| 60000|  Marketing|\n",
      "| 10|   Jack| 33| 80000|Engineering|\n",
      "| 11|   Kate| 26| 50000|         HR|\n",
      "| 12|   Lily| 34| 75000|  Marketing|\n",
      "| 13|   Mike| 28| 60000|Engineering|\n",
      "| 14|  Nancy| 30| 70000|         HR|\n",
      "| 15|  Oscar| 32| 80000|  Marketing|\n",
      "+---+-------+---+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"data/sample.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34706f6e-a2db-4319-a549-046e347b95cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbc545-cf72-48ca-be2e-09f282adfcb2",
   "metadata": {},
   "source": [
    "## Window Functions - More advanced \"Aggregations\"\n",
    "\n",
    "> Window functions allow you to perform calculations across a set of rows that are related to the current row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e191b9f-3054-45e7-a9d3-83a71133f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------+-----------+-----------+\n",
      "| id|   name|age|salary| department|salary_rank|\n",
      "+---+-------+---+------+-----------+-----------+\n",
      "|  4|  David| 40| 90000|Engineering|          1|\n",
      "|  2|    Bob| 35| 80000|Engineering|          2|\n",
      "| 10|   Jack| 33| 80000|Engineering|          2|\n",
      "| 13|   Mike| 28| 60000|Engineering|          4|\n",
      "|  7|   Gina| 27| 55000|Engineering|          5|\n",
      "|  1|  Alice| 30| 70000|         HR|          1|\n",
      "|  8|  Harry| 31| 70000|         HR|          1|\n",
      "| 14|  Nancy| 30| 70000|         HR|          1|\n",
      "|  5|    Eva| 28| 60000|         HR|          4|\n",
      "| 11|   Kate| 26| 50000|         HR|          5|\n",
      "| 15|  Oscar| 32| 80000|  Marketing|          1|\n",
      "|  6|  Frank| 32| 75000|  Marketing|          2|\n",
      "| 12|   Lily| 34| 75000|  Marketing|          2|\n",
      "|  9|    Ivy| 29| 60000|  Marketing|          4|\n",
      "|  3|Charlie| 25| 50000|  Marketing|          5|\n",
      "+---+-------+---+------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, rank\n",
    "\n",
    "# Define a window partitioned by 'department' and ordered by 'salary' in descending order\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "# Apply the window function to compute the rank of employees within their department\n",
    "df_with_rank = df.withColumn(\"salary_rank\", rank().over(window_spec))\n",
    "df_with_rank.show()\n",
    "\n",
    "# The 'Window.partitionBy' divides data into groups (departments),\n",
    "# and 'orderBy' sorts employees within each group by salary in desc order. \n",
    "# The 'rank' function assigns a rank to each row based on the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbc435-964b-4dac-b9cc-1c4bc4560c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
